{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, import data and structure them appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to import the data, structure and statistically reduce them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arrays_frame(filenames, n=12):\n",
    "    ''' Returns a list, to be appended to a DataFrame, \n",
    "        with entries vectors of length 2*n with n EAR values and n boolean values describing the blinking.\n",
    "        \n",
    "        INPUT:\n",
    "            - filenames: an iterable containing the names if the .csv files to use.\n",
    "                         The files must be made of two columns, one with ear values one with 0 or 1 for the blink stamps\n",
    "            - n: the length of EAR values to use around the blink\n",
    "            \n",
    "        OUTPUT:\n",
    "            - the pd.DataFrame with the arrays of length n+1\n",
    "    '''\n",
    "    \n",
    "    data_list=[]      # appending values to a list and then appending the list to DataFrame is less expensive\n",
    "    \n",
    "    for filename in filenames:\n",
    "        data=pd.read_csv(filename, header=None)\n",
    "        \n",
    "        l=data.shape[0]\n",
    "        for i in range(n//2+1, l-n//2):\n",
    "            tmp= data[i-n//2: i+n//2]\n",
    "            tmp= tmp.values\n",
    "            tmp= tmp.flatten()\n",
    "            tmp=np.append(tmp[0::2],\n",
    "                          data.iloc[i, 1])\n",
    "            tmp= tmp.reshape(n+1)\n",
    "            \n",
    "            data_list.append(tmp)\n",
    "    \n",
    "    # STATISTICAL TREATMENT\n",
    "    # Since we want to have the same number of succesful and not succesful rows, \n",
    "    # randomly delete rows with last value 0 till I have the same number of 0 and 1.\n",
    "    # We also normalize the data\n",
    "    \n",
    "    data_frame= pd.DataFrame(data_list)\n",
    "    data_frame.iloc[:, -1]= data_frame.iloc[:, -1].apply(int)\n",
    "    \n",
    "    n_blinks= data_frame.iloc[:,-1].sum()\n",
    "    n_tot= data_frame.shape[0]\n",
    "    \n",
    "    to_keep= rnd.sample(set((data_frame.index[data_frame.iloc[:,-1]==0]).values),\n",
    "                          n_blinks)\n",
    "    \n",
    "    mask= pd.Series((range(data_frame.shape[0]))).isin(to_keep) | data_frame.iloc[:, -1]==1\n",
    "    \n",
    "    data_frame= data_frame[mask]\n",
    "    data_frame.iloc[:,:-1]= normalize(data_frame.iloc[:,:-1], copy=True)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data with the function above. Returns the DataFrame to train the models with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (722, 13)\n",
      "There are 361 blinks and 361 non-blinks in the frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350926</td>\n",
       "      <td>0.339526</td>\n",
       "      <td>0.336249</td>\n",
       "      <td>0.349676</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>0.209653</td>\n",
       "      <td>0.209653</td>\n",
       "      <td>0.199516</td>\n",
       "      <td>0.193708</td>\n",
       "      <td>0.270915</td>\n",
       "      <td>0.271841</td>\n",
       "      <td>0.314706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.323041</td>\n",
       "      <td>0.309529</td>\n",
       "      <td>0.297391</td>\n",
       "      <td>0.311573</td>\n",
       "      <td>0.305418</td>\n",
       "      <td>0.153124</td>\n",
       "      <td>0.165540</td>\n",
       "      <td>0.261665</td>\n",
       "      <td>0.261378</td>\n",
       "      <td>0.318798</td>\n",
       "      <td>0.327537</td>\n",
       "      <td>0.352825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.351462</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.342289</td>\n",
       "      <td>0.343070</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.152897</td>\n",
       "      <td>0.152906</td>\n",
       "      <td>0.203240</td>\n",
       "      <td>0.198659</td>\n",
       "      <td>0.282941</td>\n",
       "      <td>0.282941</td>\n",
       "      <td>0.321546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.280283</td>\n",
       "      <td>0.291296</td>\n",
       "      <td>0.280868</td>\n",
       "      <td>0.300499</td>\n",
       "      <td>0.293182</td>\n",
       "      <td>0.284459</td>\n",
       "      <td>0.285662</td>\n",
       "      <td>0.285107</td>\n",
       "      <td>0.292601</td>\n",
       "      <td>0.283904</td>\n",
       "      <td>0.283904</td>\n",
       "      <td>0.301366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.318569</td>\n",
       "      <td>0.337807</td>\n",
       "      <td>0.328501</td>\n",
       "      <td>0.328501</td>\n",
       "      <td>0.338445</td>\n",
       "      <td>0.328338</td>\n",
       "      <td>0.167913</td>\n",
       "      <td>0.200931</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.276548</td>\n",
       "      <td>0.262302</td>\n",
       "      <td>0.287345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "3    0.350926  0.339526  0.336249  0.349676  0.338624  0.209653  0.209653   \n",
       "55   0.323041  0.309529  0.297391  0.311573  0.305418  0.153124  0.165540   \n",
       "77   0.351462  0.353965  0.342289  0.343070  0.353965  0.152897  0.152906   \n",
       "93   0.280283  0.291296  0.280868  0.300499  0.293182  0.284459  0.285662   \n",
       "107  0.318569  0.337807  0.328501  0.328501  0.338445  0.328338  0.167913   \n",
       "\n",
       "           7         8         9         10        11  12  \n",
       "3    0.199516  0.193708  0.270915  0.271841  0.314706   1  \n",
       "55   0.261665  0.261378  0.318798  0.327537  0.352825   1  \n",
       "77   0.203240  0.198659  0.282941  0.282941  0.321546   1  \n",
       "93   0.285107  0.292601  0.283904  0.283904  0.301366   0  \n",
       "107  0.200931  0.223173  0.276548  0.262302  0.287345   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=12\n",
    "data_all=arrays_frame(['andrea1.csv',\n",
    "                       'martina.csv',\n",
    "                       'davide1.csv',\n",
    "                       'nicolo3.csv',\n",
    "                       'gaia.csv',\n",
    "                       'altea.csv',\n",
    "                       'nicolo1.csv',\n",
    "                       'martina3.csv',\n",
    "                       'martina4.csv',\n",
    "                       'matteo1.csv',\n",
    "                       'enrico.csv',\n",
    "                       'umberto.csv',\n",
    "                       'tosi.csv',\n",
    "                       'nicolo4.csv',\n",
    "                       'ale_bella.csv',\n",
    "                       'maura_base2.csv',\n",
    "                       'eddie_vedder.csv'\n",
    "                      ],\n",
    "                      n) \n",
    "\n",
    "print('Data shape: {}'.format(data_all.shape))\n",
    "print('There are {} blinks and {} non-blinks in the frame'.\n",
    "      format(data_all.iloc[:,-1].sum(),\n",
    "             (data_all.iloc[:,-1]==0).sum()))\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try some classifiers to test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= data_all.iloc[:, :-1]\n",
    "y= data_all.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Cross Validation Summary *****\n",
      "R2 score on fold-1 = [0.5]\n",
      "R2 score on fold-2 = [0.5]\n",
      "R2 score on fold-3 = [0.5]\n",
      "R2 score on fold-4 = [0.5]\n",
      "R2 score on fold-5 = [0.5]\n",
      "R2 score on fold-6 = [0.5]\n",
      "R2 score on fold-7 = [0.5]\n",
      "R2 score on fold-8 = [0.5]\n",
      "R2 score on fold-9 = [0.5]\n",
      "R2 score on fold-10 = [0.5]\n",
      "\n",
      "Average R2 score: 0.5\n"
     ]
    }
   ],
   "source": [
    "modelB= BernoulliNB()\n",
    "\n",
    "cv_scores = cross_val_score(modelB, X, y, cv=10)\n",
    "\n",
    "print(\"***** Cross Validation Summary *****\")\n",
    "for v in range(0, len(cv_scores)):\n",
    "    print(\"R2 score on fold-{} = [{}]\".format(v+1, cv_scores[v]))\n",
    "    \n",
    "print('\\nAverage R2 score: {}'.format(cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Cross Validation Summary *****\n",
      "R2 score on fold-1 = [0.8243243243243243]\n",
      "R2 score on fold-2 = [0.7916666666666666]\n",
      "R2 score on fold-3 = [0.875]\n",
      "R2 score on fold-4 = [0.9027777777777778]\n",
      "R2 score on fold-5 = [0.75]\n",
      "R2 score on fold-6 = [0.8055555555555556]\n",
      "R2 score on fold-7 = [0.7222222222222222]\n",
      "R2 score on fold-8 = [0.6666666666666666]\n",
      "R2 score on fold-9 = [0.8055555555555556]\n",
      "R2 score on fold-10 = [0.75]\n",
      "\n",
      "Average R2 score: 0.789376876876877\n"
     ]
    }
   ],
   "source": [
    "modelS= SVC()\n",
    "\n",
    "cv_scores = cross_val_score(modelS, X, y, cv=10)\n",
    "\n",
    "print(\"***** Cross Validation Summary *****\")\n",
    "for v in range(0, len(cv_scores)):\n",
    "    print(\"R2 score on fold-{} = [{}]\".format(v+1, cv_scores[v]))\n",
    "    \n",
    "print('\\nAverage R2 score: {}'.format(cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Cross Validation Summary *****\n",
      "R2 score on fold-1 = [0.8108108108108109]\n",
      "R2 score on fold-2 = [0.7222222222222222]\n",
      "R2 score on fold-3 = [0.9027777777777778]\n",
      "R2 score on fold-4 = [0.8611111111111112]\n",
      "R2 score on fold-5 = [0.875]\n",
      "R2 score on fold-6 = [0.7361111111111112]\n",
      "R2 score on fold-7 = [0.7222222222222222]\n",
      "R2 score on fold-8 = [0.8194444444444444]\n",
      "R2 score on fold-9 = [0.75]\n",
      "R2 score on fold-10 = [0.7083333333333334]\n",
      "\n",
      "Average R2 score: 0.7908033033033033\n"
     ]
    }
   ],
   "source": [
    "modelD= DecisionTreeClassifier()\n",
    "\n",
    "cv_scores = cross_val_score(modelD, X, y, cv=10)\n",
    "\n",
    "print(\"***** Cross Validation Summary *****\")\n",
    "for v in range(0, len(cv_scores)):\n",
    "    print(\"R2 score on fold-{} = [{}]\".format(v+1, cv_scores[v]))\n",
    "\n",
    "print('\\nAverage R2 score: {}'.format(cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Cross Validation Summary *****\n",
      "R2 score on fold-1 = [0.8648648648648649]\n",
      "R2 score on fold-2 = [0.75]\n",
      "R2 score on fold-3 = [0.8888888888888888]\n",
      "R2 score on fold-4 = [0.9444444444444444]\n",
      "R2 score on fold-5 = [0.8611111111111112]\n",
      "R2 score on fold-6 = [0.8333333333333334]\n",
      "R2 score on fold-7 = [0.8611111111111112]\n",
      "R2 score on fold-8 = [0.8194444444444444]\n",
      "R2 score on fold-9 = [0.875]\n",
      "R2 score on fold-10 = [0.8333333333333334]\n",
      "\n",
      "Average R2 score: 0.8531531531531531\n"
     ]
    }
   ],
   "source": [
    "modelF= RandomForestClassifier()\n",
    "\n",
    "cv_scores = cross_val_score(modelF, X, y, cv=10)\n",
    "\n",
    "print(\"***** Cross Validation Summary *****\")\n",
    "for v in range(0, len(cv_scores)):\n",
    "    print(\"R2 score on fold-{} = [{}]\".format(v+1, cv_scores[v]))\n",
    "\n",
    "print('\\nAverage R2 score: {}'.format(cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now import a data set to test and try all the classifiers above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10 blinks\n"
     ]
    }
   ],
   "source": [
    "test= arrays_frame(['andrea1.csv'], n)\n",
    "test_values= test.iloc[:, :-1]\n",
    "test_res= test.iloc[:, -1]\n",
    "\n",
    "print('There are {} blinks'.format(test_res.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_= modelB.fit(X,y)\n",
    "_= modelS.fit(X,y)\n",
    "_= modelD.fit(X,y)\n",
    "_= modelF.fit(X,y)\n",
    "\n",
    "predB= modelB.predict(test_values)\n",
    "predS= modelS.predict(test_values)\n",
    "predD= modelD.predict(test_values)\n",
    "predF= modelF.predict(test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now import some raw data to make actual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data(filenames, n=12):\n",
    "    ''' Imports the data and arrange them to be used for the prediction\n",
    "        \n",
    "        INPUT:\n",
    "            - filenames: an iterable containing the names if the .csv files to use, they have to be a double column\n",
    "            - n: the length of the array of EAR values to use\n",
    "            \n",
    "        OUTPUT:\n",
    "            - the pd.DataFrame with the arrays of length n\n",
    "    '''\n",
    "    \n",
    "    data_list=[]      # appending values to a list and then appending the list to DataFrame is less expensive\n",
    "    \n",
    "    for filename in filenames:\n",
    "        data=pd.read_csv(filename, header=None)\n",
    "        data= data.iloc[:,1]\n",
    "        \n",
    "        l=data.shape[0]\n",
    "        for i in range(n//2+1, l-n//2):\n",
    "            tmp= data[i-n//2: i+n//2]\n",
    "            tmp= tmp.values\n",
    "            tmp= tmp.flatten()\n",
    "            \n",
    "            data_list.append(tmp)\n",
    "    \n",
    "    \n",
    "    data_frame= pd.DataFrame(data_list)\n",
    "    normalize(data_frame.iloc[:,:-1])\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of predictions would be correct if we made a grouping of consecutive 1s.\n",
    "### Let's make a function to do so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Processed prediction \n",
      " [1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0] \n",
      "Real prediction \n",
      " [1 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "def process_prediction(array_orig):\n",
    "    array=array_orig.copy()\n",
    "    i=0\n",
    "    while i<len(array)-1:\n",
    "        if array[i]==1:\n",
    "            count=0\n",
    "            j=i\n",
    "            zero_count=0\n",
    "            while j<len(array) and (array[j]==1 or (zero_count<=1 and array[j-1]==1)):\n",
    "                count+=1\n",
    "                j+=1\n",
    "                if array[i]==0:\n",
    "                    zero_count+=1\n",
    "                \n",
    "            if count>1:\n",
    "                array[i+1:i+count]=0\n",
    "            i=j\n",
    "        elif array[i]==0:\n",
    "            i+=1\n",
    "    return array\n",
    "\n",
    "\n",
    "pred= modelF.predict(test_values) \n",
    "print(pred.sum())\n",
    "print('Processed prediction \\n',\n",
    "      process_prediction(pred),\n",
    "      '\\nReal prediction \\n',\n",
    "      pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to plot the blinking frequency, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequency(data, fps=28.5, N=60):\n",
    "    ''' Plot the frequency of the blinks, computed over the last N seconds\n",
    "        \n",
    "        INPUT:\n",
    "            - data: a pd.Series or np 1-dimensional array\n",
    "            - fps: frames per second of the video, allowas to transfrom from frames to time\n",
    "            - N: the number of previous frames to compute the frequency over. Makes the frequency more or less sensitive\n",
    "        OUTPUT:\n",
    "            - the list with the frequencies on any frame computed over the previous N frames\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    freq=[]\n",
    "    \n",
    "    for i in range(N,len(data)):\n",
    "        freq.append( data.iloc[i:i+N].mean() *60 *fps )\n",
    "    \n",
    "    return freq   \n",
    "\n",
    "#d=pd.read_csv('eardata.csv').iloc[:, 1]\n",
    "\n",
    "#_=plt.plot(frequency(d, 28.5, 200)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make function to make a frame from the ear values array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arrange_raw(raw_data, n=12):\n",
    "    '''\n",
    "        INPUT: a pd.Series with only ear values\n",
    "        OUTPUT: a pd.DataFrame to feed the classifier\n",
    "    '''\n",
    "    tmp= raw_data.values.tolist()\n",
    "    \n",
    "    array=[]\n",
    "\n",
    "    for i in range(n,len(tmp)):\n",
    "        array.append(tmp[i-n:i])\n",
    "    \n",
    "    data_frame=pd.DataFrame(array)\n",
    "    normalize(data_frame.iloc[:,:-1])\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 39 blinks in the video\n",
      "[0 0 0 ..., 0 0 0]\n",
      "There are 41 blink in the video\n",
      "[0 0 0 ..., 0 0 0]\n",
      "Total number of frames: 1654\n",
      "Error rate:0.0012091898428053204\n"
     ]
    }
   ],
   "source": [
    "gaia= pd.read_csv('eddie_vedder.csv')\n",
    "\n",
    "X=gaia.iloc[:,0]\n",
    "y=gaia.iloc[:,1]\n",
    "\n",
    "\n",
    "\n",
    "gaia_pred= process_prediction(modelS.predict(arrange_raw(X,n))) \n",
    "\n",
    "predicted_blinks=gaia_pred.sum()\n",
    "real_blinks=y.sum()\n",
    "\n",
    "print('Predicted {} blinks in the video'.format(predicted_blinks))\n",
    "print(gaia_pred)\n",
    "\n",
    "print('There are {} blink in the video'.format(real_blinks))\n",
    "print(np.array(y))\n",
    "\n",
    "print('Total number of frames: {}'.format(len(y)))\n",
    "\n",
    "print('Error rate:{}'.format(abs(predicted_blinks-real_blinks)/len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try some video to be compared with the algorithmic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verify_video(filename):\n",
    "    \n",
    "    tmp=pd.read_csv(filename, header=None)\n",
    "    fps=1/(tmp.iloc[1,0])\n",
    "    print(fps)\n",
    "    ear_frame= arrange_raw(tmp.iloc[:,1])\n",
    "    y=process_prediction(modelS.predict(ear_frame))\n",
    "\n",
    "    \n",
    "    print('Video length in seconds: {}'.format(len(y)/fps))\n",
    "    print('The number of blinks predicted is {}'.format(y.sum()))\n",
    "    print('They have been detected at the following times:')\n",
    "    print((np.array(range(len(y)))[y==1])/fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0702963648\n",
      "Video length in seconds: 124.80754943243971\n",
      "The number of blinks predicted is 82\n",
      "They have been detected at the following times:\n",
      "[   2.09509076    2.49415566    3.82437202    5.45388705    5.88620737\n",
      "    9.84360102   13.63471763   14.99818939   18.49000732   19.68720204\n",
      "   20.21928858   22.5471672    22.81321047   25.67317564   27.43571231\n",
      "   27.96779885   31.09380728   32.291002     34.48585898   36.21514024\n",
      "   36.94675924   37.97767691   39.90649063   41.33647321   42.10134761\n",
      "   46.02548586   47.18942517   48.71917397   49.05172806   52.01145945\n",
      "   53.57446367   55.03770165   56.46768424   57.831156     58.86207367\n",
      "   59.52718185   59.85973594   60.72437657   61.35622934   61.9548267\n",
      "   62.52016865   63.28504305   64.11642827   66.31128526   66.64383935\n",
      "   70.50146677   70.93378709   71.66540608   73.76049684   74.42560502\n",
      "   76.58720659   79.91274748   81.54226251   83.63735327   84.03641818\n",
      "   84.40222767   88.69217542   94.71140442   95.27674637   96.47394109\n",
      "   97.93717908   98.66879807  100.43133474  103.72362022  105.48615689\n",
      "  106.48381915  107.08241651  107.44822601  108.67867614  112.27026029\n",
      "  113.89977533  114.23232942  114.76441596  115.42952414  117.79065816\n",
      "  118.62204339  120.25155842  121.24922068  121.58177477  122.74571408\n",
      "  123.1780344   124.54150616]\n"
     ]
    }
   ],
   "source": [
    "verify_video('./comparison_videos/altea/eardata_altea_lie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
